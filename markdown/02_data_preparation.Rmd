---
title: "Data preparation"
date: "September, 2019"
---

```{r setup_preparation, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.pos =  "h")
knitr::opts_knit$set(root.dir = "../")

# loading required libraries and scripts
library(knitr)
```


```{r scripts_evaluation, include=FALSE}
# loading required steps before performing the analysis
source("./src/datapreparation/step_02_data_ingestion.R")
source("./src/datapreparation/step_03_data_cleaning.R")
```

# Using a step by step approach

Before starting the analysis for the Spatial-Statistics, a few important steps were taken in order to prepare the source data files. These steps are listed below:

- **Step 01**: Config Environment;
- **Step 02**: Data Ingestion;
- **Step 03**: Data Cleaning;
- **Step 04**: Label Translation;
- **Step 05**: Data Enhancement;
- **Step 06**: Dataset Preparation.

*******************************************************************************

# Config Environment (step 1)
This step do an initial setup configuration for the project.

``` {r config_environment, eval = FALSE}

# clearing everything before starting -----------------------------------------
# clear environment and memory
rm(list=ls())
invisible(gc())

# clear console screen
cat("\014")

# clear plots
while (!is.null(dev.list()))  
  dev.off()

# setting the environment -----------------------------------------------------
options(encoding = "UTF-8")

info.username  <- Sys.info()[["user"]]
info.sysname   <- Sys.info()[["sysname"]]
info.machine   <- Sys.info()[["machine"]]
info.encoding  <- getOption("encoding")
directoryPath  <- dirname(rstudioapi::getSourceEditorContext()$path)
directoryPath  <- stringr::str_replace(directoryPath, "/src/datapreparation", "")

setwd(directoryPath)
getwd()

```

*******************************************************************************

# Data Ingestion (step 2)
The process of data ingestion — preparing data for analysis — usually includes steps called extract (taking the data from its current location), transform (cleansing and normalizing the data), and load (placing the data in a database where it can be analyzed).

``` {r data_ingestion, eval = FALSE}

# performing data loading -----------------------------------------------------
dataRawDirectory <- "./data/raw/"
shapefile_to_read <- paste(dataRawDirectory, "crime_mg.shp", sep = "")

target <- readOGR(shapefile_to_read, encoding="UTF-8")

```

*******************************************************************************

# Data Cleaning (step 3)

The objective of this step is analysing missing values and other strange conditions. In order to accomplish this task, a few R functions were used to quickly discover missing values, like NA and empty fields.

The command below was used to find out any NA values in each table.

``` {r find_na, eval = FALSE}
sapply(TableName, function(x) sum(is.na(x)))
```

There was no tables with NA values:

```{r transaction_na_cols, echo=FALSE, results = 'asis'}
kable(mytable_na_cols)
```

Finally, the following command was used in each table to find out where empty values was hidden. 

``` {r find_empty, eval = FALSE}
sapply(TableName, function(x) table(as.character(x) =="")["TRUE"])
```

There was no tables with empty values:

```{r echo=FALSE, results = 'asis'}
kable(mytable_empty_cols)
```

For the exploration analysis report, we did not take any additional action, since the missing values was not relevant.

There are 33 cities in which the variables POP_RUR, POP_URB, POP_FEM, POP_MAS, POP_TOT have zero in their values, however the column POP_94 has value greater than zero. so, the strategy is to produce the value for the missing columns based on the average values for the rest of cities in Minas Gerais.

The following adjustments were taken:

```{r echo=FALSE, results = 'asis'}

# converting columns from text to numeric
target$POP_RUR <- as.numeric(as.character(target$POP_RUR))
target$POP_URB <- as.numeric(as.character(target$POP_URB))
target$POP_FEM <- as.numeric(as.character(target$POP_FEM))
target$POP_MAS <- as.numeric(as.character(target$POP_MAS))

# getting rural population and female's mean ratio
target.dataframe <- as(target, "data.frame")
target.dataframe <- filter(target.dataframe, POP_RUR != 0)
poprur.ratio <- mean(target.dataframe$POP_RUR) / mean(target.dataframe$POP_URB)
pophm.ratio  <- mean(target.dataframe$POP_MAS) / mean(target.dataframe$POP_FEM)
popfem.ratio <- mean(target.dataframe$POP_FEM) / mean(target.dataframe$POP_TOT)

# adjusting rows with zero in POP_RUR, POP_URB, POP_FEM, POP_MAS and POP_TOT
target$POP_RUR <- ifelse(target$POP_RUR == 0, 
                         round(target$POP_94 * poprur.ratio, digits = 0),
                         round(target$POP_RUR, digits = 0))
target$POP_URB <- ifelse(target$POP_URB == 0, 
                         round(target$POP_94 - target$POP_RUR, digits = 0),
                         round(target$POP_URB, digits = 0))
target$POP_FEM <- ifelse(target$POP_FEM == 0, 
                         round(target$POP_94 * popfem.ratio, digits = 0),
                         round(target$POP_FEM, digits = 0))
target$POP_MAS <- ifelse(target$POP_MAS == 0, 
                         round(target$POP_94 - target$POP_FEM, digits = 0),
                         round(target$POP_MAS, digits = 0))
target$POP_TOT <- ifelse(target$POP_TOT == 0, 
                         round(target$POP_94, digits = 0),
                         round(target$POP_TOT, digits = 0))

```

*******************************************************************************

# Label Translation (step 4)
In order to make the data information more understandable, it was translated some relevant labels and domains from Czech to English.

For this project this step is not required.

*******************************************************************************

# Data Enhancement (step 5)
This step aims to improve the analysis by adding auxiliary information. Data enhancement is all about making sure any data that is coming into the business is being looked at with a critical eye and is being filtered down to maximize its value.

For this project this step is not required.

*******************************************************************************

# Data Preparation for the Spatial Statistics (step 6)

## Selecting the target dataset

The below function was created to be used in the modeling exercises to be performed, the idea is to have a standard way to get the prepared data set already prepared with correct data types and dummies.

``` {r data_prep, eval = FALSE}

dataProcessedDirectory <- "./data/processed/"
shapefile_to_write <- paste(dataProcessedDirectory, "crime_mg_processed.shp", sep = "")
writeOGR(target, 
         dsn = shapefile_to_write, 
         driver ="ESRI Shapefile", 
         layer = "cities", 
         overwrite_layer = TRUE)

```